{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObArTU/BQiYOE/UHW16Qi0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArjunBalaji79/dockingscore_app_streamlit/blob/main/GCN_CCG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import all neccesary Libraries"
      ],
      "metadata": {
        "id": "sx0p-HpP-ueF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch_geometric\n",
        "! pip install scipy\n",
        "! pip install rdkit\n",
        "import sklearn.metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score, mean_squared_error"
      ],
      "metadata": {
        "id": "LqOZ5W6w-yVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting SMILES to Graph"
      ],
      "metadata": {
        "id": "5zRIYF1S_Bdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/ORGANS/BRAIN/Proccesed_Brain_Q00535.csv')\n",
        "\n",
        "# Defining the smiles_to_graph function\n",
        "def smiles_to_graph(smiles):\n",
        "    molecule = Chem.MolFromSmiles(smiles)\n",
        "    if molecule is None:\n",
        "        return None\n",
        "    molecule = Chem.AddHs(molecule)\n",
        "\n",
        "    num_atoms = molecule.GetNumAtoms()\n",
        "\n",
        "    # Simple feature representation: one-hot encoding for atom types (C, O, N, B)\n",
        "    atom_features = np.zeros((num_atoms, 4))\n",
        "\n",
        "    for atom in molecule.GetAtoms():\n",
        "        atom_type = atom.GetSymbol()\n",
        "        if atom_type == 'C':\n",
        "            atom_features[atom.GetIdx()][0] = 1\n",
        "        elif atom_type == 'O':\n",
        "            atom_features[atom.GetIdx()][1] = 1\n",
        "        elif atom_type == 'N':\n",
        "            atom_features[atom.GetIdx()][2] = 1\n",
        "        elif atom_type == 'B':\n",
        "            atom_features[atom.GetIdx()][3] = 1\n",
        "\n",
        "    bond_indices = []\n",
        "    bond_features = []\n",
        "\n",
        "    for bond in molecule.GetBonds():\n",
        "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "        bond_indices.extend([(start, end), (end, start)])  # Adding edges for both directions here\n",
        "\n",
        "        # Bond feature representation\n",
        "        bond_type = bond.GetBondType()\n",
        "        is_in_ring = bond.IsInRing()\n",
        "\n",
        "        bond_feature = [\n",
        "            1 if bond_type == Chem.rdchem.BondType.SINGLE else 0,\n",
        "            1 if bond_type == Chem.rdchem.BondType.DOUBLE else 0,\n",
        "            1 if bond_type == Chem.rdchem.BondType.TRIPLE else 0,\n",
        "            1 if bond_type == Chem.rdchem.BondType.AROMATIC else 0,\n",
        "            1 if is_in_ring else 0\n",
        "        ]\n",
        "\n",
        "        bond_features.extend([bond_feature, bond_feature.copy()])  # Adding feature for both bond directions here\n",
        "\n",
        "    return {\n",
        "        'atom_features': atom_features,\n",
        "        'bond_indices': bond_indices,\n",
        "        'bond_features': bond_features,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "2uIcVB5w_FpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting SMILES strings to molecular graphs and creating a list of Data objects\n",
        "data_list = []\n",
        "for index, row in data.iterrows():\n",
        "    smiles = row['SMILES']\n",
        "    affinity = row['Y(Obs)']\n",
        "    graph = smiles_to_graph(smiles)\n",
        "    if graph is not None:\n",
        "        x = torch.tensor(graph['atom_features'], dtype=torch.float32)\n",
        "        edge_index = torch.tensor(graph['bond_indices'], dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(graph['bond_features'], dtype=torch.float32)\n",
        "        y = torch.tensor([affinity], dtype=torch.float32)\n",
        "        data_list.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n"
      ],
      "metadata": {
        "id": "dnFqOQ2P_JSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN Model"
      ],
      "metadata": {
        "id": "bYzNd3By_S4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 layer GNN model\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, num_features, hidden_dim, dropout_rate=0.5):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.dropout(x)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "L2hbihZ8_OlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation"
      ],
      "metadata": {
        "id": "-C-lsP9M_kNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initializing the model and training parameters\n",
        "batch_size = 32\n",
        "num_epochs = 150\n",
        "patience = 25"
      ],
      "metadata": {
        "id": "DWY5XAEU_ZVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation loop\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(data_list)):\n",
        "    train_data = DataLoader([data_list[i] for i in train_idx], batch_size=batch_size, shuffle=True)\n",
        "    val_data = DataLoader([data_list[i] for i in val_idx], batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = GNNModel(num_features=4, hidden_dim=128, dropout_rate=0.5)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    best_val_loss = np.inf\n",
        "    best_epoch = -1\n",
        "    early_stop_counter = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for data in train_data:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, data.y.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_data)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data in val_data:\n",
        "                output = model(data)\n",
        "                val_loss = criterion(output, data.y.view(-1, 1))\n",
        "                total_val_loss += val_loss.item()\n",
        "        avg_val_loss = total_val_loss / len(val_data)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Checkpoint model if validation loss improved\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), f'best_gnn_model_fold_{fold}.pth')\n",
        "            early_stop_counter = 0\n",
        "        else:\n",
        "            early_stop_counter += 1\n",
        "            if early_stop_counter >= patience:\n",
        "                print(f'Early stopping at epoch {epoch + 1}')\n",
        "                break\n"
      ],
      "metadata": {
        "id": "qN4Pvb40_XCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the best model and evaluating on the validation set\n",
        "model.load_state_dict(torch.load(f'best_gnn_model_fold_{fold}.pth'))\n",
        "model.eval()\n",
        "actual_affinities = []\n",
        "predicted_affinities = []\n",
        "with torch.no_grad():\n",
        "  for data in val_data:\n",
        "\n",
        "    output = model(data)\n",
        "    actual_affinities.extend(data.y.view(-1).cpu().numpy())\n",
        "    predicted_affinities.extend(output.view(-1).cpu().numpy())"
      ],
      "metadata": {
        "id": "GcI3gtPf_oXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    rmse = np.sqrt(mean_squared_error(actual_affinities, predicted_affinities))\n",
        "    mae = mean_absolute_error(actual_affinities, predicted_affinities)\n",
        "\n",
        "    # Append per-fold results to check later\n",
        "    fold_results['rmse_scores'].append(rmse)\n",
        "    fold_results['mae_scores'].append(mae)\n",
        "    fold_results['actual_affinities'].extend(actual_affinities)\n",
        "    fold_results['predicted_affinities'].extend(predicted_affinities)\n",
        "\n",
        "    # Ploting training/validation loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
        "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'Fold {fold+1} Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "VtVFGnI6_8XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print overall evaluation metrics\n",
        "overall_rmse = np.sqrt(mean_squared_error(fold_results['actual_affinities'], fold_results['predicted_affinities']))\n",
        "overall_mae = mean_absolute_error(fold_results['actual_affinities'], fold_results['predicted_affinities'])\n",
        "print(f'Overall RMSE: {overall_rmse:.4f}')\n",
        "print(f'Overall MAE: {overall_mae:.4f}')"
      ],
      "metadata": {
        "id": "Tsh3i6DQAIJW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}